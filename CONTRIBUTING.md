# AIM Contributing Guide

We are really excited that you are interested in contributing to AIM! Before submitting your contribution though, please make sure to take a moment and read through the following instructions and guidelines.


## Extending AIM with New Metrics

AIM has been designed from the ground-up with extensibility in mind. As a result, new metrics can be added with relatively small effort, but there are a few steps that need to be followed.

First, the new metric should be defined in a separate Python file and placed under a proper subdirectory within the [aim_metrics](./aim_metrics/aim_metrics/) directory. The entry point to the metric must be a function called `execute`, and it must take as a parameter a base64 encoded image (PNG or JPG) representation of the web page. Segmentation-based metrics must take as an additional parameter to this a list of page elements, generated by the segmentation script. The `execute` function must return a list of results, which must have at least one entry. The result entries must be *int*, *float*, or a *base64* encoded image representation of the web page.

Metrics are executed on the backend by the [metric_executor.py](./aim_backend/uimetrics_backend/metric_executor.py) file. The metric must be imported here, and it must to be registered to the list of executable metrics. Each list entry has the metric ID as key and a dictionary of options as value. The dictionary specifies the type of the metric (`png` for pixel-based, `jpg` for pixel-based, or `seg` for segmentation-based) and the imported metric module itself.

In addition to the backend, the metric must be registered on the frontend too to show up on the list of metrics. This is done in the [metrics.js](./aim_frontend/src/config/metrics.js) file. Here, a new entry must be added in the JSON under the `metrics` key. Each entry’s key is its metric ID.

**Table 1.** Description of `metrics` entry in `metrics.js`

| Key               | Description |
|:------------------|:------------|
| id                | Metric ID   |
| name              | Metric name. Will be displayed in list of metrics on the frontend |
| category          | Metric category ID |
| description       | Description of the metric |
| evidence          | 1-5 `int`; rating of evidence for this metric |
| relevance         | 1-5 `int`; rating of relevance for this metric |
| speed             | 0-2 `int`; 0=slow, 1=medium, 2=fast, will be displayed as ‘Computation time’ |
| visualizationType | `table` or `b64`, table=numerical results, b64=image results |
| references        | List of `references` entries specifying references, cf. description below |
| results           | List of `results` entries specifying results, cf. description below |

**Table 2.** Description of `references` entry in `metrics.js`

| Key      | Description |
|:---------|:------------|
| title    | Reference title, will be shown in a tooltip when hovering over the reference number |
| fileName | Name of the PDF file of the reference paper |

**Table 3.** Description of `results` entry in `metrics.js`

| Key         | Description |
|:------------|:------------|
| id          | Result ID, format is metric ID + underscore + index in the array returned by the metric |
| index       | Index in metric result array |
| type        | `int`, `float`, or `b64` |
| name        | Result name |
| description | Optional description of the result. `false` if there is no description |

Every metric also must be added under a proper `category` at the start of the same file. A new category can also be created.

**Table 4.** Description of `categories` entry in `metrics.js`

| Key     | Description |
|:--------|:------------|
| id      | Category ID |
| name    | Category name |
| color   | Name of the CSS class in `AIMForm.vue` specifying the category color |
| metrics | List of metric IDs belonging to this category |

After adding a new metric, the frontend must be restarted with `npm run dev` for development or recompiled with `npm run build` for production (executed in the [aim_frontend](./aim_frontend/) directory). For the backend, the AIM metrics package must be reinstalled with `pip install ../aim_metrics` and the server must be relaunched with `python uimetrics_backend/main.py` (executed in the [aim_backend](./aim_backend/) directory).


## Credits

Big thank you to all the people who have already contributed to AIM!

Antti Oulasvirta, Samuli De Pascale, Janin Koch, Thomas Langerak, Jussi Jokinen, Kashyap Todi, Markku Laine, Manoj Kristhombuge, Yuxi Zhu, Aliaksei Miniukovich, Gregorio Palmas, and Tino Weinkauf.